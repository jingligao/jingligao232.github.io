
<html>

<head>
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <link rel="shortcut icon" href="paper_dragon.ico">
    <link rel="stylesheet" type="text/css" href="style.css" />
    <!-- <link rel="shortcut icon" href="paper_dragon.ico"> -->
    <title>Jingli Gao's Publications</title>
    <base href="https://jingligao.github.io/index.html">
    <!-- <base href="./index.html"> -->

</head>

<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<h1 style="padding-left: 0.5em">Jingli Gao (Associate Professor at PDSU)</h1><hr>
<td id="layout-menu">
    <div class="menu-item"><a href="index.html">Home</a></div>
    <div class="menu-item"><a href="groups.html">Group</a></div>
    <div class="menu-item"><a href="talks.html">Talks</a></div>
    <div class="menu-item"><a href="teaching.html">Teaching</a></div>
    <div class="menu-item"><a href="service.html">Service</a></div>
    <div class="menu-item"><a href="research.html">Research</a></div>
    <div class="menu-item"><a href="publications.html">Publications</a></div>
    <div class="menu-item"><a href="code.html">Codes & Data</a></div>
    <div class="menu-item"><a href="award.html">Awards & honours</a></div>
</td>
<td id="layout-content">
    <h1 style="margin-top: 0em">Research (Selected Topics)</h1>
   <div>
        <h2><hr>
        Intelligent security</h2>
		<img src="research-security.png" width=380 height="200" border="0" align="right"/>
        Object detection is the entrance of computer vision, which is very critical in the fields of automatic driving, intelligent security, machine vision and so on. Object detection is used to determine whether a certain area of the image contains the object of interest, and  then accurately find the object.  
        <h3>Relevant Work/Publications:</h3>
  <ul>
              
         <li><p>Low-altitude, slow-speed, small-target detection in the stationary background
            [<a href="https://ieeexplore.ieee.org/document/8244071">CAC’17</a>, <a href="http://en.cnki.com.cn/Article_en/CJFDTOTAL-SHJT201506023.htm">JSJU’15</a>]</p>
         </li>
        <li>
          <p>Low-altitude, slow-speed, small-target detection in the slowly changing background [<a href="http://www.engineering.org.cn/en/10.1631/FITEE.1601203">FITEE’16</a>]</p>
        </li>
        <li><p>Low-altitude, slow-speed, small-target detection in the fast changing background
 [<a href="papers/Sensors-Detection.pdf">Sensors’17</a>]</p>
        </li>
        <li>Surface defect detection  [<a href="https://ieeexplore.ieee.org/document/6852386">CCDC’14</a>]</li>
        </ul>
    </div>
	
	<div>
            <h2><hr>Intelligent Medical Care</h2>
			<img src="research-medical.png" width=380 height="160" border="0" align="right"/>
Intelligent medical care  is a recently emerging proprietary medical term. 
   Through the creation of a medical information platform, the interaction between patients and medical staff, medical institutions, and medical equipment can be realized, and the quality of medical care can be effectively improved.
<h3>Relevant Work/Publications:</h3>
  <ul>
         <li>
           <p>Medical image understanding </p>
         </li>
         <li>Oral digital medical technology</li>
        </ul>
     </div>
	   
            <h2><hr></a>Robust/Adversarial learning</h2>
We are also interested in how to reduce the side effect of noise on the instance, which may be caused by the failure of sensors or even malicious attacks. We human have the ability to correctly recognise the objects even there are noise (e.g., we can easily recognise human faces under extreme illumination conditions, when partially occluded, or even with heavy makeup); while current machine learning algorithms may not. Recent studies also show that an imperceptible noise on the instance will lead machines to make wrong decisions. All those mean that we human and machines are using different feature extraction mechanisms for making decisions. What are the differences? And how to align them? Answering those questions is very important to build robust and trustworthy machine learning algorithms.   
    <h3>Relevant Work/Publications:</h3>
  <ul>
               <li><p>Towards defending against adversarial examples via attack-invariant features [<a href="">ICML’20</a>]</p></li>
         <li><p>Efficient gradient approximation for black boxes [<a href="http://proceedings.mlr.press/v119/zhang20o/zhang20o.pdf">ICML’20</a>]</p></li>
         <li><p>Understanding adversarial attacks via maximum mean discrepancy [<a href="https://arxiv.org/pdf/2010.11415.pdf">ICML’21</a>]</p></li>
                     <li><p>Learning diverse-structured networks for adversarial robustness [<a href="">ICML’20</a>]</p></li>
         <li><p>Robust non-negative matrix factorisation algorithms [<a href="https://ieeexplore.ieee.org/document/7492255">TNNLS’17</a>, <a href="https://ojs.aaai.org//index.php/AAAI/article/view/5991">AAAI’20</a>]</p></li>
         <li><p>Compare the robustness of different loss functions [<a href="https://ieeexplore.ieee.org/document/6920341">ICIST’14</a>, <a href="https://arxiv.org/abs/1906.00495">TPAMI’19</a>]</p></li>
      </ul>

    
                <h2><hr></a>Statistical (deep) learning theory</h2>
Deep learning algorithms have given exciting performances, e.g., painting pictures, beating Go champions, and autonomously driving cars, among others, showing that they have very good generalisation abilities (small differences between training and test errors). These empirical achievements have astounded yet confounded their human creators. Why do deep learning algorithms generalise so well on unseen data? It lacks mathematical elegance. We do not know the underlying principles that guarantee its success. Let alone to interpret or pertinently strengthen its generalisation ability. We are interested in analysing error bounds, e.g., generalisation error bound and excess risk bound, by measuring the complexity of the predefined (or algorithmic) hypothesis class. An algorithmic hypothesis class is a subset of the predefined hypothesis class that a learning algorithm will (or is likely to) output.
    <h3>Relevant Work/Publications:</h3>
<ul>
         <li><p>The relationship between algorithmic stability and algorithmic hypothesis complexity [<a href="http://proceedings.mlr.press/v70/liu17c/liu17c.pdf">ICML’17</a>]</p></li>
         <li><p>Control batch size and learning rate to generalize well [<a href="https://papers.nips.cc/paper/2019/file/dc6a70712a252123c40d2adba6a11d84-Paper.pdf">NeurIPS’19</a>]</p></li>
              <li><p>On the Rates of Convergence from Surrogate Risk Minimizers to the Bayes Optimal Classifier [<a href="https://arxiv.org/pdf/1802.03688.pdf">TNNLS’accepted</a>]</p></li>
         <li><p>Understanding the generalisation of ResNet [<a href="https://arxiv.org/abs/1904.01367">TNNLS’20</a>]</p></li>
         <li><p>Understanding the generalisation of orthogonal deep neural networks [<a href="https://arxiv.org/abs/1905.05929">TPAMI’accepted</a>]</p></li>
         <li><p>Understanding the generalisation of multi-task learning [<a href="https://ieeexplore.ieee.org/document/7437460">TPAMI’17</a>]</p></li>
         <li><p>Understanding how feature structure transfers in transfer learning [<a href="https://www.ijcai.org/Proceedings/2017/0329.pdf">IJCAI’17</a>]</p></li>
         <li><p>Understanding the generalisation of non-negative matrix factorisation [<a href="https://arxiv.org/pdf/1601.00238.pdf">NECO’16</a>, <a href="https://ieeexplore.ieee.org/document/7192641">TNNLS’16</a>, <a href="https://ieeexplore.ieee.org/document/7492255">TNNLS’17</a>]</p></li>
      </ul>

    
</td>
</tr>
</table>
</body>
</html>
